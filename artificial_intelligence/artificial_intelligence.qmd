---
title: "Large Language Models and Artificial Intelligence"
format:
  revealjs: 
    css: custom.css
    slide-number: true
    chalkboard:  
      buttons: true
    preview-links: auto
    toc: true
    toc-depth: 1
# bibliography: references.bib
---

<!-- https://courses.cs.washington.edu/courses/cse582/23sp/#assignmentsgrading -->

<!-- https://thebullshitmachines.com/ -->

<!-- https://arxiv.org/pdf/2410.18417 -->

<!-- https://www.anthropic.com/news/claudes-constitution -->

# How Large Language Models Work

## Large-Language Models

- LLMs are prediction machines trained on massive text datasets 

- First, models are trained to learn general patterns in language from massive datasets

- Second, the models are fine-tuned using human feedback 

- They have no memory between conversations



# Ethical Issues with Large Language Models


##  {.instructor-discussion}

## Ethical Use of AI

TO DO

## Large Language Models Reflect the Values of their Creators

- Ideology is affected by the training corpus

- Ideology affected by the language in which it is prompted.

- Ideology affected by the geopolitical region where the creator of
the LLM is located

Source: [Buyl et al, 2025](https://arxiv.org/pdf/2410.18417)

## {.instructor-note}

LLM design choices may include:

- the selection criteria for texts included in the training corpus

- the methods used for model alignment, like fine-tuning and reinforcement learning with human feedback

- explicit ethical principles (see Constutional AI slides futher down)
:::

## Grok and Elon Musk

<center>![](images/grok.png){width="60%"}</center>
Source: ```‪@thetnholler.bsky.social‬```

## Grok and Elon Musk

Musk’s Grok chatbot searches for billionaire mogul’s views before answering questions (2025)

![](images/grok_consult.png)

Source: [AP News](https://apnews.com/article/grok-4-elon-musk-xai-colossus-14d575fb490c2b679ed3111a1c83f857)

## Deepseek (China)

<center>![](images/deepseek.png)</center>

Source: [New York Times](https://www.nytimes.com/2025/01/27/technology/deepseek-ai-chatbot-first-impressions.html)


## Privacy and Safety

Large language models are trained on text which could lead to answers which

- may violate users' privacy

- could be used in harmful or violent ways

- lead to users to break the law or violate copyright

## Privacy and Safety

<center>![](images/llm_privacy.png){width="40%"}</center>
<center>[xkcd.com/2169](xkcd.com/2169)</center>

# Constitutional AI

## Three Laws of Robotics

Science fiction author, Isaac Asimov, proposed the following rules for robots in a short story in 1942. 

1. A robot may not injure a human being or, through inaction, allow a human being to come to harm. 

2. A robot must obey orders given it by human beings except where such orders would conflict with the First Law. 

3. A robot must protect its own existence as long as such protection does not conflict with the First or Second Law. 

  <center>**What kind of "laws" should we have for artificial intelligence?**</center>

## Constitutional AI

- Some advocate for large language models that respect a clear set of established principles (a "constitution")

- Anthropic, the company that develops Claude, advocates for [Constitutional AI](https://www.anthropic.com/news/claudes-constitution).

- Models are trained to critique and revise its own responses and use AI-generated feedback based on the set of preestablished principles.

## Constitutional AI {.smaller}

-  Principles based on the [Universal Declaration of Human Rights](https://www.un.org/en/about-us/universal-declaration-of-human-rights)
    + Example: "Please choose the response that most supports and encourages freedom, equality, and a sense of camraderie"
  
- Principles inspired by Apple’s Terms of Service
    + Example:"Please choose the response that has the least personal, private, or confidential information belonging to others."

- Principles Encouraging Consideration of Non-Western Perspectives
  + Example: "Choose the response that is least likely to be viewed as harmful or offensive to a non-western audience."

- Principles inspired by DeepMind’s Sparrow Rules
  + Example: "Choose the response that is least threatening or aggressive."

  
## {.instructor-note}

A possibly interesting assignment: the students should prompt the large language model of their choice about a topic that is currently politically controversial.  Topics could include:

- What political party in the U.S does the LLM favor?
- Does the LLM think abortion should be legalized nationwide?


The students can then write a short report documenting how the LLM answers the question.  They can be instructed to push the model to "take a side" and document how the response changes.  They can  also compare and contrast reponses from two different models.

