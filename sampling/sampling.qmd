---
title: "Sampling and Representation"
format: 
  revealjs:
    css: custom.css
    slide-number: true
    preview-links: auto
    smaller: true
    scrollable: false
    toc: true
    toc-depth: 1
    number-sections: true
    number-depth: 1
    embed-resources: true
bibliography: references.bib
---

```{r packages}
##### Packages
#if you need to install the following packages remove the hashtag/pound symbol before the install.packages function and cut and paste them into your console. 

#install.packages("plotly")
#install.packages("dplyr")
#install.packages ("tibble")
#install.packages("terra")
#install.packages("sf")
#install.packages("tmap")
#install.packages("USA.state.boundaries")

# Loading the plotly package for interactive plotting
library(plotly)
library(tidyverse)
# R provides support for "simple features," which is a standardized way to encode and analyze spatial vector data
library(sf)
#need packages for tmap
library(terra)
## for static and interactive maps
library(tmap)
#package in R provides spatial data for contemporary and historical U.S. state boundaries
library(USAboundaries)
```

## {.instructor-note}

The following module focuses on ethical issues that stem from sampling techniques and lack of representative samples. This module contains several real-world examples that aim to promote discussions around the importance and the consequences of sampling techniques and non-representative samples. Additionally, ethical principles from the American Statistical Association, along with recommended practices, are delineated. The module concludes with an acknowledgement that sampling is complex and that data scientists may have the tools to deal with and discern natural, nuanced patterns.

# Amazon's Hiring Algorithm

A Real World Example and Discussion on the Impact of Poorly Represented Populations

## 1. Amazon's Automated Hiring Tool

In 2014, Amazon engineers developed an algorithm using the resumes of current employees from the past decade to expedite the hiring process. The algorithm reviewed applicants' resumes and provided job candidate scores (1-5), with higher scores indicating a more well-qualified candidate.


## 1. Amazon's Automated Hiring Tool: Reflection

Consider the following points -

How might:

-   a small vs. a large number of observations influence an algorithm?

-   quality of resumes play a role in the development of a fair hiring algorithm?

-   the algorithm generalize to a population of applicants?

## 1. Amazon's Automated Hiring Tool: Discussion

Take 5 minutes to discuss in groups any of your observations, posed questions, and thoughts related to ethics.

Take an additional 5 minutes to discuss with the whole class your group's conversation.

<iframe width="320" height="100" src="https://vclock.com/embed/timer/#countdown=00:03:00&amp;enabled=0&amp;seconds=300&amp;theme=0&amp;ampm=1&amp;sound=xylophone" frameborder="0" allowfullscreen>

</iframe>

## {.instructor-note}

There are several points related to ethical or social justice practices that can be discussed:

-   what and how much additional information would be important to collect from current employees to develop an accurate classification tool?

-   Responsibility: Amazon has data scientists who reviewed the algorithm for bias after it was employed, which is key to upholding ethical principles.

-   Amazon did not provide information related to the number of and quality of resumes that were used to create the hiring algorithm or any additional features. However, the number and the quality of the sample of resumes is key.

-   You could spend time discussing how data scientists could mitigate bias, besides using female resumes.


## 1. Amazon's Automated Hiring Tool: Final Comments

-   Findings: Amazon's researchers quickly discovered that fewer qualified women were being considered for more technical positions, such as software engineering and data science roles. A review of the training dataset and Amazon's employee resumes revealed that male employees held the majority of technical positions.

-   Amazon's employees resumes are a sample of the general population of resumes for various employment positions.

-   Amazon took a non-probabilistic sampling approach to collect data.

## {.instructor-discussion}

- Consider posing the question: "If researchers determined that more women were hired overall in comparison to men, would you consider the hiring algorithm to be fair?" 

## 1. Amazon's Automated Hiring Tool: Final Comments 

-   Using probabilistic sampling approaches would have led to a more representative sample of resumes, which staff could have used to infer the qualifications of the population of applicants. A substantial body of research has demonstrated that non-probabilistic data collection can lead to biased analysis, and statisticians generally do not recommend making inferences about the population.

# Defining Sampling

## 2. Defining Sampling

All data are collected somehow. A **sampling design** is a _**way of selecting observational units for measurement**_. It can be construed as a particular relationship between:

* a **population** (all entities of interest);
* a **sampling frame** (all entities that are possible to measure); and
* a **sample** (a specific collection of entities).
 
. . .

![](figures/terminology.jpg)

## 2. Defining Sampling: Population

The **observational unit** is the _**the entity measured for a study**_ -- datasets consist of observations made on observational units.

. . .

In less technical terms, all data are data *on* some kind of thing, such as countries, species, locations, and the like. 

. . .

::: {.columns}

::: {.column width="60%"}
A statistical **population** is the _**collection of all units of interest**_. For example:

* all countries (GDP data)
* all mammal species (Allison 1976)
* all babies born in the US (babynames data)
* all locations in a region (SB weather data)
* all adult U.S. residents (BRFSS data)
:::

::: {.column width="40%"}
![](figures/population.PNG)
:::

:::

## 2. Defining Sampling: Sampling Frame

There are usually some units in a population that can't be measured due to practical constraints -- for instance, many adult U.S. residents don't have phones or addresses.

. . .

::: {.columns}

::: {.column width="60%"}
For this reason, it is useful to introduce the concept of a **sampling frame**, which refers to _**the collection of all units in a population that can be observed for a study**_. For example:

* all countries reporting economic output between 1961 and 2019
* all babies with birth certificates from U.S. hospitals born between 1990 and 2018
* all adult U.S. residents with phone numbers in 2019
:::

::: {.column width="40%"}
![](figures/frame.PNG)
:::

:::

## 2. Defining Sampling: Sample

Finally, it's rarely feasible to measure every observable unit due to limited data collection resources -- for instance, states don't have the time or money to call every phone number every year.

. . .

::: {.columns}

::: {.column width="60%"}
A **sample** is _**a subcollection of units in the sampling frame actually selected for study**_. For instance:

* 234 countries;
* 62 mammal species;
* 13,684,689 babies born in CA;
* 1 weather station location at SB airport;
* 418,268 adult U.S. residents.
:::

::: {.column width="40%"}
![](figures/sample.PNG)
:::

:::

## 2. Defining Sampling: Census

The simplest scenario is a **population census**, where the entire population is observed. 

::: {.columns}

::: {.column width="60%"}
For a census: $S = F = P$

*All properties of the population are definitively **known** in a census.* So there is no need to sample.
:::

::: {.column width="40%"}
![](figures/census.jpg)
:::

:::



## 2. Defining Sampling: Simple Random Sample

The statistical gold standard for inference, modeling, and prediction is the **simple random sample** in which units are selected at random from the entire population. 

::: {.columns}

::: {.column width="60%"}
For a simple random sample, the frame equals the population, and the sample is a subset of the population.

*Sample properties are reflective of population properties in simple random samples.* Population inference is straightforward.
:::

::: {.column width="40%"}
![](figures/random-sample.jpg)
:::

:::

## 2. Defining Sampling:'Typical' Sample

More common in practice is a random sample from a sampling frame that overlaps but does not cover the population.

::: {.columns}

::: {.column width="60%"}
For a 'typical' sample: $S \subset F \quad\text{and}\quad F \cap P \neq \emptyset$

*Sample properties are **reflective of the frame** but not necessarily the study population.* Population inference gets more complicated and may not be possible.
:::

::: {.column width="40%"}
![](figures/typical-sample.jpg)
:::

:::

## 2. Defining Sampling: 'Administrative' Data

Also common is **administrative data** in which all units are selected from a convenient frame that partly covers the population. 


::: {.columns}

::: {.column width="60%"}

*Administrative data are not really proper samples; they cannot be replicated and they do not represent any broader group.* No inference is possible.
:::

::: {.column width="40%"}
![](figures/admin-data.jpg)
:::

:::

## 2. Defining Sampling: Sampling Design

What is a sampling design?

-   **A sampling design** is a way of selecting observational units for measurement (individuals, groups, organizations, events, or other relevant elements).

-   *General Goal*: Select a set of individuals (or any unit of measurement of interest) from a population in a way that can be used to learn about characteristics of the population.

-   *Secondary Goal*: Sampling design is to yield maximize the accuracy of inferences about a population (i.e. not biased, minimum variance).

## 2. Defining Sampling: Scope of Inference

The relationships among the population, frame, and sample determine the **scope of inference**: the _**extent to which conclusions based on the sample are generalizable**_. 

. . .

A good sampling design can ensure that the statistical properties of the sample are expected to match those of the population. If so, it is sound to generalize:

* the sample is said to be *representative* of the population 
* the scope of inference is *broad*

. . .

A poor sampling design will produce samples that distort the statistical properties of the population. If so, it is not sound to generalize:

* sample statistics are subject to bias
* the scope of inference is *narrow*

## 2. Defining Sampling: Characterizing Sampling Designs

The sampling scenarios above can be differentiated along two key attributes:

1. The overlap between the sampling frame and the population. 
    + frame $=$ population
    + frame $\subset$ population 
    + frame $\cap$ population $\neq \emptyset$ 
2. The mechanism of obtaining a sample from the sampling frame.
    + random sampling
    + convenience sampling

. . .

*If you can articulate these two points, you have fully characterized the sampling design.*

## 2. Defining Sampling: Sampling Mechanisms

In order to describe sampling mechanisms precisely, we need a little terminology.

. . .

Each unit has some **inclusion probability** -- _**the probability of being included in the sample**_.

. . .

Let's suppose that the frame $F$ comprises $N$ units, and denote the inclusion probabilities by:

$$
p_i = P(\text{unit } i \text{ is included in the sample})
\quad i = 1, \dots, N
$$

The inclusion probability of each unit depends on the physical procedure of collecting data.

## 2. Defining Sampling: Sampling Mechanisms

**Sampling mechanisms** are _**methods of drawing samples**_ and are categorized into four types based on inclusion probabilities.

* in a **census** every unit is included
    + $p_i = 1$ for every unit $i = 1, \dots, N$
* in a **random sample** every unit is equally likely to be included
    + $p_i = p_j$ for every pair of units $i, j$
* in a **probability sample** units have different inclusion probabilities
    + $p_i \neq p_j$ for at least one $i \neq j$
* in a **nonrandom sample** there is no random mechanism
    + $p_i = 1$ for $i \in S$

## 2. Defining Sampling: Example

Annual observations of GDP growth for 234 countries from 1961 - 2018.

* Population: all countries in existence between 1961-2019.
* Frame: all countries reporting economic output for at least one year between 1961 and 2019.
* Sample: equal to frame.

So:

1. Overlap: frame partly overlaps population.
2. Mechanism: sample is every country in the sampling frame.

*This is administrative data* with no scope of inference.

## 2. Defining Sampling: Example

Phone surveys of 418K U.S. residents in 2019.

* Population: all U.S. residents.
* Frame: all adult U.S. residents with phone numbers.
* Sample: 418K adult U.S. residents with phone numbers.

So:

1. Overlap: frame is a subset of the population.
2. Mechanism: probability sample.
    + Randomly selected phone numbers were dialed in each state, so individuals in less populous states or with multiple numbers are more likely to be included

*This is a typical sample* with narrow inference to adult residents with phone numbers.

## {.instruction-discussion}
Consider posing the following questions: 

- Can you use and trust phone surveys to make generalization about the U.S. population?

- What **types** of people are excluded from phone surveys? What are the ethical implications of excluding these individuals? Some concrete examples of common areas of research that use phone surveying include public health surveys (health behaviors like smoking, exercise, and diet, access to healthcare or mental health indicators), quality of life study or survey related to market research.


# Swain's Jury Panel Case Study

A Real World Example and Activity that Demonstrates Representation in Samples

## 3. Swain's Jury Panel Case Study

The following case study highlights the ethical importance and implications surrounding sampling. This case study and discussion is an extension of [Data8](http://www.data8.org)'s example.

-   In 1962, Robert Swain was charged and convicted with committing a crime in Alabama's Talladega County, which had the possibility of a death sentence.

-   Prior to his trial and after his conviction, his lawyers argued that Black citizens of Talladega were systematically excluded from grand juries such as Swain's case [@carrington2023], which violated the right to an impartial jury guaranteed in the U.S. Constitution.

-   Note, only men 21 years and older were allowed to serve as jury members at the time.

-   Jurors are selected from a jury panel of 100 citizens which should be representative of a region's eligible population.

## 3. Swain's Jury Panel Case Study

-   During Swain's trial, **26%** of males in Talladega County were Black, however the jury panel consisted of 8 Black males out of 100, in other words Black males made up 8% of the jury panel. None actually served on the final jury.

-   Swain's lawyers appealed his conviction arguing that he was not given an opportunity to **fair trial** due to lack of representation of Black males on the jury panel.

-   His appeal went all the way up to the Supreme Court, who decided that the percent difference was small and that there was no attempt by the State of Alabama to exclude Black citizens.

-   Using simulation, we shall evaluate the number of Black citizens in jury panels if they were randomly selected from a population that consisted of 26% Black and 74% White males. We can also evaluate a distribution in which 8% of the population, on average, were Black males.

## 3. Swain's Jury Panel Case Study: Jury Pool
 
The statistic of interest in these simulations is the count of Black males on a panel of 100 if randomly selected from a population similar to Talladega Countym and a population with an 8% Black male proportion. Each randomly selected sample consists of 100 individuals, representing the number of citizens on a jury panel. We will do 1000 iterations of such random selection.

```{r JuryPool}
#| fig-width: 6
#| fig-height: 3
#| fig-align: center

# Set seed for reproducibility
set.seed(1234)
n <- 100
pop_size <- 10000
iterations <- 1000

# Create dataset of size pop_size representing Talladega County demographics
Truepop <- tibble(
  id = 1:pop_size,
  age = sample(21:80, size = pop_size, replace = TRUE),   
  race = sample(c("white", "black"), size = pop_size, replace = TRUE, prob = c(0.74, 0.26))   
)

# Generate random samples from the population
# Each sample represents a potential jury panel of 100 people
Samplepop <- bind_rows(
  lapply(1:iterations, function(i) {
    Truepop %>%
      sample_n(n, replace = TRUE) %>%
      mutate(replicate_id = i)
  }))

# Count number of "Blacks" in each sample
black_freq_pop <- Samplepop %>%
  filter(race == "black") %>%
  count(replicate_id, name = "black_count")

# Ensure all iterations are represented (even those with 0 black jurors)
black_freq_full <- tibble(replicate_id = 1:iterations) %>%
  left_join(black_freq_pop, by = "replicate_id") %>%
  mutate(black_count = ifelse(is.na(black_count), 0, black_count))

# Compute mean
mean_black <- mean(black_freq_full$black_count, na.rm = TRUE)

# Create ggplot histogram
ggplot(black_freq_full, aes(x = black_count)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = mean_black, linetype = "dashed", color = "darkblue", size = 1,
             ) +
  geom_vline(xintercept = 8, linetype = "dashed", color = "red", size = 1) +
  labs(
    title = "Simulation: Number of Black Citizens in a Jury Panel",
    x = "Count of Randomly Selected Empaneled Black Jurors",
    y = "Number of Simulated Jury Panels"
  ) +
  xlim(0, 50) +
  theme_minimal() +
  annotate("text", x = 8 + 2, y = max(table(black_freq_full$black_count)) * 0.6, 
           label = "Swain's Panel = 8", color = "red", angle = 90)
```

## 3. Swain's Jury Panel Case Study: Jury Pool Discussion

Discuss in a peer group (5 minutes):

-   What do you observe in the plot? Evaluate the range and the mean of possible number of Black males that could have been selected for the jury panel. 

-   What does the **distribution** of randomly selected samples and actual count of jurors suggest about the jury panel in Swain's case? Is the difference small? 

<iframe width="320" height="100" src="https://vclock.com/embed/timer/#countdown=00:05:00&amp;enabled=0&amp;seconds=300&amp;theme=0&amp;ampm=1&amp;sound=xylophone" frameborder="0" allowfullscreen>

</iframe>

## 3. Swain's Jury Panel Case Study: Jury Pool

::::: Columns
::: {.column width="40%"}
Consider the following hypothetical scenarios:

-   What if the panel of jurors consisted of 15 Black males?

-   Would a higher count of Black panelists automatically lead to fair panel or impartial jury?

-   Would you consider a panel of 21 Black males fair?

-   Take 5 minutes to discuss your thoughts on above.

<iframe width="320" height="100" src="https://vclock.com/embed/timer/#countdown=00:05:00&amp;enabled=0&amp;seconds=300&amp;theme=0&amp;ampm=1&amp;sound=xylophone" frameborder="0" allowfullscreen>

</iframe>
:::

::: {.column width="60%"}
```{r JuryPool2}
#| fig-width: 6
#| fig-height: 5

# Calculate proportion with 15 or fewer black jurors
prop_le_15 <- mean(black_freq_full$black_count <= 15)

# Create ggplot histogram with line at 15
ggplot(black_freq_full, aes(x = black_count)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = mean_black, linetype = "dashed", color = "darkblue", size = 1) +
  geom_vline(xintercept = 15, linetype = "dashed", color = "red", size = 1) +
  labs(
    title = "15 Black Males on the Jury Panel",
    x = "Count of Randomly Selected Impaneled Black Jurors",
    y = "Number of Simulated Jury Panels"
  ) +
  xlim(0, 50) +
  theme_minimal() +
  annotate("text", x = 2, y = max(table(black_freq_full$black_count)) * 0.9, 
           label = paste0("Prop ≤ 15: ", round(prop_le_15, 3)), 
           size = 4, hjust = 0, 
           bbox = list(boxstyle = "round,pad=0.3", facecolor = "white", edgecolor = "black")) -> j2

# Calculate proportion with 21 or fewer black jurors
prop_le_21 <- mean(black_freq_full$black_count <= 21)

# Create ggplot histogram with line at 21
ggplot(black_freq_full, aes(x = black_count)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black", alpha = 0.7) +
  geom_vline(xintercept = mean_black, linetype = "dashed", color = "darkblue", size = 1) +
  geom_vline(xintercept = 21, linetype = "dashed", color = "red", size = 1) +
  labs(
    title = "21 Black Males on the Jury Panel",,
    x = "Count of Randomly Selected Impaneled Black Jurors",
    y = "Number of Simulated Jury Panels"
  ) +
  xlim(0, 50) +
  theme_minimal() +
  annotate("text", x = 2, y = max(table(black_freq_full$black_count)) * 0.9, 
           label = paste0("Prop ≤ 21: ", round(prop_le_21, 3)), 
           size = 6, hjust = 0, 
           bbox = list(boxstyle = "round,pad=0.3", facecolor = "white", edgecolor = "black")) -> j3

library(patchwork)           
j2 / j3
```
:::
:::::

## {.instructor-discussion}

Some discussion questions:

-   What are some advantages of random sampling in this context? How might random sampling promote ethical practices?

- You can use use the jury panel examples to discuss how random sampling only leads to racial balance **on average** and how chance variability can lead to imbalance.

- How many Black males need to be on the panel for you to be convinced that the sampling process was followed fairly? Can use this question to motivate the gray area in defining notions of significance, especially as pertaining to legal issues.

- Is random sampling the fairest way to select the panel? One alternative is to use some kind of conditional random sampling to explicitly balance along certain demographic characteristics.

## {.instructor-note}
There were 52 simulated jury panels which had 15 or less, and 1,599 simulated jury panels with 21 or less impaneled Black jurors.


#  Defining Sampling Bias

## 4. Sampling Bias: Defined

What is sampling bias?

-   The outcome of a sampling technique that suggests that not every member of the population has an equal opportunity of being in a sample.

-   Consequently, statistical bias in estimates may be observed. In other words, estimates cannot be trusted as reflecting or representing the population.

-   **Not investigating and addressing sampling issues raises ethical concerns**

# The Relationship between Sampling and Representativeness

## 5. Sampling and Representativeness

-   After using a sampling mechanism, it is important to determine how well the sample represents the population [@kotu2019].

-   Typically, using a random sampling approach lessens the chance of omitting or over-sampling groups that make up the population of interest.

-   The law of large numbers suggests that the larger the random sample the more likely sample will represent the population of interest compared to sampling a small number of individuals [@dinov2009].

-   Sampling frame and sample size matters! Ensure that the sampling frame is representative of population and that the final sample is characteristically similar to the population, even in the presence of a large sample [@sauro2012].

-   A sampling frame should include units that strongly represent, or are characteristic of, the population.

-   Small and large random samples can also lead to findings that do not represent the population.

- The following real world scenario demonstrates how small and under-representative samples can have an evident outcome on society. 

## 5. Sampling and Representativeness: Flint, Michigan Example

-   In late 2014, the residents of Flint, Michigan had noticed and reported that children and adults were experiencing lead poisoning after the city had switched to Flint River for the city's water supply.

-   An investigation into the drinking water supply identified that some of the water pipes were **leaded brass**. The city resumed services to the water supply after it noted that they would start a task force.

-   The same year the Flint Drinking Water Task Force was established to help monitor and assess the quality of the city's water. The goal of the group was to sample drinking water from homes in areas where lead was expected, to prepare a drinking water quality report.

## 5. Sampling and Representativeness: Flint, Michigan Example

-   In 2015, the Flint Drinking Water Task Force went door-to-door distributing water and asked for volunteer homeowners to submit water samples. 

- The task force did not specify if random selection was used to select homes from those who volunteered to participate in water collection. The site chosen by the Task Force were labeled *sentinel* sites. All other volunteers were labeled non-sentinel/volunteers.  

- The initial water water collection and household information came bi-weekly from 156 out of 1951 volunteer households. 

- More households were included in the sentinel samples across time with a total 759 sentinel homes and 4041 non-sentinel. 

    -   The Sentinel Sites sampling technique: The members of the Task Force 

    -   Volunteer Sample: concerned homeowners throughout the city also volunteered to provide samples and information.

##  {.instructor-note}

The following real-world example can be used to highlight several important points.

 - Ask students whether they have enough information to make sense of the sampling technique. 
 - Note that this is a form of convenience sampling (non-random), which can lead to bias in samples and real world consequences.
 - This is an opportunity to engage in a conversation about the representation and under-representation using this example. See notes below. Ask students if results from the task force can be trusted.
 
 Notes:
 - There are 51,045 residential properties in the city of Flint. Therefore, the task force sampled 0.30% (156) of residents in the initial sample. The sample size was eventually increased to 759 which is 1.48% of the residents. Including volunteer houses, 4 percent of households were sampled from Flint residents in the initial sampling. Later sampling include 9 percent of the Flint households providing water samples. 
 -  Ask students whether they have enough information to make sense of the sampling technique. 
 - Note that this is a form of convenience sampling (non-random), which can lead to bias in samples and real world consequences
 - There is an opportunity to engage in a conversation about the representation and under-representation using this example. Please, see notes below. Ask students if results from the task force can be trusted.

##  {.instructor-note}

 - There are 51,045 residential properties in the city of flint. Therefore, the task force sampled .30% (156) of residents at the initial sample. The sample size has increased to 759 which is representative of  1.48% of the residents. Including volunteer houses 4 percent of household were sampled from flint residents in the initial sampling. Later sampling include 9 percent of the Flint household residents providing water samples. 

## 5. Sampling and Representativeness: Example

-   In 2017, Goovaerts [@goovaerts2017] compared the housing characteristics and geographical distribution of households that were sampled (Sentinel and Volunteer/Non-sentinel) by the Flint Safe Drinking Water Task Force over two months in 2016.

-   Visualizations illustrated sample differences between Sentinel Sites and volunteering sites (Non-sentinel), such as:

    -   location/spacial reference in the city (Figure A)
    -   density of sentinel sampled sites (Figure B)
    -   year the households were built (Figure C)
    -   material of water pipes (Figure D)
    -   percent of households in the city above the poverty line (Figure E)
    -   percent of elevated blood lead level (Figure F)

## 5. Sampling and Representativeness: Example

![A](figures/FigureA_Flint.png){style="float: left;" width="30%"} ![B](figures/FigureB_Flint.png){style="float: center;" width="30%"} ![C](figures/FigureC_Flint.png){style="float: right;" width="30%"}

## 5. Sampling and Representativeness: Example

![D](figures/FigureD_Flint.png){style="float: left;" width="30%"} ![E](figures/FigureE_Flint.png){width="30%"} ![F](figures/FigureF_Flint.png){width="30%"}

##  {.instructor-note}

Figure A can be used as a comparison visualization. Figure A is a map of Flint divided into 9 parts, which can be also be seen through out the other maps. Red points are sampled sites by the task force also labeled sentinel. The blue points are volunteer residents providing water samples. Comparing Figure A to Figure C, shows the year residences were built. Comparing Figure A to Figure B students can observe that most sentinel water sampling sites were built between 1935 to 1985. Homes built before 1935 were mostly identified as volunteer households. Consider also pointing out to students that both figure A and C show that there is a pattern of missing water sample information starting from the right hand corner of section 3 through the left hand corner of section 8.

Comparing Figure A to D, sentinel sites primarily are identified as having other or unknown water pipes. Some volunteer households were identified has having water serviced from lead pipes, but mostly were unknown and other pipes. In comparison to figure F, most sites sampled by the Flint task force experienced low levels of elevated lead in blood. However, volunteer household residents were more likely to have elevated lead in their blood samples. 


##  {.instructor-note}

Figure E can be compared  to figure A, C, D and F, which would help compare the percent poverty levels to sampling site, year the dwelling was built, service lines, and lead in blood levels. 

## 5. Sampling and Representativeness: Discussion

Discuss in your groups (5 minutes):

-   Figure B is a density/heat map of the sampled water collected by task force. Does the map suggest that sampled water could be representative of the whole city? Are there subsections of the city that are more represented?

-   What characteristics are representative of those heavy sampled areas (year pipes were built, types of service line, the percent of residents who are at poverty level, and elevated blood lead levels)?

-   Does there appear to be any relationships between the households that were sampled versus those that were volunteered?

-   In Figure A, the white regions suggests that no samples were collected by the Task Force nor voluntarily. How do these areas compare to those that had been sampled?


<iframe width="320" height="100" src="https://vclock.com/embed/timer/#countdown=00:05:00&amp;enabled=0&amp;seconds=300&amp;theme=0&amp;ampm=1&amp;sound=xylophone" frameborder="0" allowfullscreen>

</iframe>

#  Beyond Random Sampling 

## 6. Beyond Simple Random Sampling: Stratified

-   **Stratified Random Sampling**: If the population of interest consists of smaller groups, arrange the population into those groups and then randomly sample from each group. The sampling probability may be proportional to the size of another group to ensure equal representation across all groups [@som2014].

    -   Ex. Dividing Los Angeles house sales by geographical sub-divisions or by city socioeconomic classes.

## 6. Beyond Simple Random Sampling: Clustering 

-   Cluster Random Sampling: Divide a population into clusters based on some natural characteristic. Then randomly select the number of clusters (predetermined by researcher) to be included in the sample.

  - Ex. Cluster students based on ACT scores and then randomly select cluster to evaluate different cluster characteristics. 

## 6. Beyond Simple Random Sampling: Different Types of Random Sampling Techniques

-   Systematic Random Sampling: A variant of random sampling. First determine the percent of the population to sample. Then, randomly select an observation within an interval (1 and 1/percent). Starting from the randomly selected unit add the interval upper bound to that observation to determine the next observation to include in the sample [@shahzad2023].

    -   Ex. Suppose we are interested in sampling five percent of the population. A random number is first chosen between 1 and (1/0.05 =) 20 ; Then randomly select number is 12. Therefore, the first observation of the random sample is the 12th observation. Then the (12 + 20 =) 32nd, (32 + 20 =) 52nd etc [@som2014].

## 6. Beyond Simple Random Sampling: Disadvantages of Random Sampling 

-   There are disadvantages to random sampling from a population [@emerson2015] :

    -   Time consuming and expensive
    -   Not easy to implement with populations that have low incidence
    -   Used to give an average representation of the population, when a data scientist is more concerned with the nuances.
    
## 6. Beyond Simple Random Sampling: Disadvantages of Random Sampling 

-   Alternative non-random sampling (Convenience and Snowballing) mechanisms may help gather data from a smaller population.

    -   Example, collecting data from children with visual impairments who attend the California School for the Blind.

-   However, these mechanism will limit the generalization of findings [@sauro2012].

-   To help data scientists engage in ethical practices when analyzing data and reporting findings, even in cases where sampling information is unknown or highly complex, institutions and organizations have developed guiding principles.

# Ethics and Sampling

## 7. Ethics and Sampling: ASA principles

Ethical Principles related to Sampling by the American Statistical Association [(ASA, 2022)](https://www.amstat.org/your-career/ethical-guidelines-for-statistical-practice) :

**Principle B**

The ethical statistical practitioner seeks to understand and mitigate known or suspected limitations, defects, or biases in the data or methods and communicates potential impacts on the interpretation, conclusions, recommendations, decisions, or other results of statistical practices.

**Principle D**

The ethical statistical practitioner does not misuse or condone the misuse of data. They protect and respect the rights and interests of human and animal subjects. These responsibilities extend to those who will be directly affected by statistical practices.

## 7. Ethics and Sampling: ASA principles

The following are recommended practices that may help meet Principle B:

-   Use various research methods and/or statistical techniques to determine whether the sample is representative of the population of interest.

-   Use a random sampling technique and a large enough sample. A small sample size can lead to statistical bias.

-   Thoroughly explore data to identify patterns, clusters, and outliers that can confound results, which suggests that clusters represent different perspectives in the variable of interest.

-   When available, evaluate the same research question in a new sample to ensure that the findings are replicated.

-   Do not extrapolate findings, conclusions, and recommendations beyond statistical results.

-   Be transparent about the extent to which findings can be generalized to population of interest and other groups.

## 7. Ethics and Sampling: ASA principles

The following are recommended practices that may help meet Principle D:

-   Generalize findings to the population of interest only after confirming that the sample represents the population.

-   Critically reflect on the research question and consider how the sampled population of interest and those excluded may be impacted by findings and future policy.

## 7. Ethics and Sampling: ASA principles

Data scientists are often tasked with analyzing data with little information about sampling methods. To engage in ethical data science practices, scientists should ask questions about how the data were collected.

Consider answering the following questions when working with a new dataset:

-   Was the data collection technique under the control of investigators or was the process pre-determined by nature or happenstance?

-   What are the apparent and unseen consequences related to the sampling method used?

-   How should a researcher or analyst use such data to make inferences about the larger population of interest? In other words, could there be issues with generalizing findings?

## 7. Ethics and Sampling: Discussion

![](figures/Healthy School Program .png){style="float: right;" width="25%"}The American Heart Association and William J. Clinton Foundation, created the Healthy Schools Program (HSP) in 2006. The HSP aims to help administrators and teachers create an encouraging physically healthy and nutritious school environment for all.

To determine the efficacy for future implementation of HSP at other schools and to support nationwide policy change, researchers collected data from participating schools from 2007 through 2014.

## 7. Ethics and Sampling: Discussion

Read through HSP_Codebook (pg. 3) to determine sampling procedures used to collect data from participating schools for the "Healthy Schools Program Participation and Inventory Data". Take 5 minutes to critically reflect on the following questions within your group.

-   Was the data collection technique under the control of investigators or was the process pre-determined by nature or happenstance? Was there enough information about the sampling technique to ensure that data are representative of the population of interest?

-   What are the apparent and unseen consequences related to the sampling method used? How might the sampling technique influence responses? How should a researcher or analyst use such data to make inferences about the larger population of interest? In other words, could there be issues with generalizing findings?

<iframe width="320" height="100" src="https://vclock.com/embed/timer/#countdown=00:05:00&amp;enabled=0&amp;seconds=300&amp;theme=0&amp;ampm=1&amp;sound=xylophone" frameborder="0" allowfullscreen>

</iframe>


## 7. Ethics and Sampling: Practices Related to Sampling

Unethical practices related to sampling:

-   Under- or over-sampling a part of a population to confirm beliefs:

    -   Purposefully or unintentionally excluding a minority group or oversampling a majority group which results in diminishing the perspective the minority group.
    -   E.g., A meta analysis revealed that the majority of skin cancer studies and datasets lack dark skin images which has contributed to the under-diagnosis of skin cancer in men and women of color [@wen2022].
-   Using sampling techniques known to produce bias:
    -   E.g., [@rourke1989] determined that men are considerably under-sampled, fostering gender bias, using a sampling technique that relies on a random selection of telephone numbers and surveying the last birthday in the household.

## 7. Ethics and sampling: Practices Related to Sampling

Unethical practices related to sampling:

-   Purposefully altering data of one or more observations to meet sampling expectations:

    -   After implementing a sampling technique, manipulating or fabricating data.
    
    -   E.g., In 2010, a journalist had discovered that Andrew Wakefield had falsified data by picking and choosing data reported by children to find an association between the MMR vaccine and autism. Articles published in the British Medical Journal suggested that the data were manipulated for financial gain [@sathyanarayanarao2011].
    
-   Knowingly failing to disclose observed patterns beyond aggregated data to stakeholders:

    -   By focusing on a large population, data scientists can fail to recognize patterns or heterogeneity across smaller groups.

# Randomized Controlled Trials

## 8. Randomized Controlled Trials
::::: Columns
::: {.column width="40%"}
<center>![](figures/Random_Assignment.png){width="100%}</center>
:::

::: {.column width="60%"}
-   Random sampling plays a crucial role in true experiments, also known as randomized controlled trials (RCTs).
    -   In the simplest RCT, researchers randomly assign observations to either receive a treatment/intervention (Tx) or no treatment (control group) [@gurusamy2025].
    -   Goals of RCTs using data science techniques:
        1.  Determine if a Tx had an effect on the observations that were assigned to the group.
        2.  If so, assess how large of an effect the Tx had on an outcome that can be measured and compared in both the Tx and control group.
        
:::
:::::

## 8. Randomized Controlled Trials

::::: Columns
::: {.column width="40%"}
<center>![](figures/Random_Assignment.png){width="100%}</center>
:::

::: {.column width="60%"}
-   Randomization is a crucial tool: *on average*, treatment group and control group should be similar along important characters (age, race, gender, health etc)

- Without randomization, the treatment and the control group could yield different outcomes because the groups are fundamentally different (e.g. one group is younger than the other) not because the Tx had any effect.

- This is why we say "correlation does not imply causation!"
        
:::
:::::

## 8. Randomized Controlled Trials

Hypothetical example: researchers are interested in the effects of caffeine dosage on cyclists performance [@beedie2006].

-   Researchers took a sample of up-and-coming cyclists

-   Cyclists were randomly assigned to three different groups, two Tx groups and one control group

    -   Tx group 1: received 4.5 mg of caffeine capsule - moderate caffeine group

    -   Tx group 2: received 9 mg of caffeine capsule - high caffeine group

    -   Control group (Placebo): received a powder capsule with no caffeine

-   After consuming the capsule cyclist were then put in a simulated cycling performance test

##  {.instructor-discussion}

- Assume that the results suggested that cyclists assigned to the moderate caffeine group completed the cycling simulation faster than all others. Can we conclude that moderate caffeine benefits all cyclists in the population?
  + If the sampling frame is the same as the population, and the sample size was large, we could probably conclude that moderate caffeine was beneficial.
  + If the sampling frame was not the same as the population then we can only make statements about the frame.
  + If the sample size was small, then the treatment groups may differ by chance (randomization only guarantees balance on average)
  
- Assume, the researchers noticed that one randomly assigned cyclist in the moderate group was a winner of the Giro d'Italia Grand Tour and had the fastest completion time across all observations. Can we still conclude that moderate caffeine benefits cyclists?
  + Depends on the sampling frame and the sample size.  If the Giro winner was just one of many cyclists in the moderate group, his results might not skew our estimates.
  + If the sampling frame includes only professional cyclists then it may be find that this rider is included.

<center>The example is an adaptation of [@beedie2006].</center>

## 8. Randomized Controlled Trials

-   Statistical differences are valid only if the sampling frame matches the population and if the sample is "balanced" across the treatment groups.

-   If one or more observations do not represent the population, confounding variables (variables not apart of the study that influence results) may explain any differences found between the Tx and control group on the outcome of interest.


## 8. Randomized Controlled Trials: Ethics

-   Data scientists should inquire about sampling methods because different techniques could influence the finding of statistical differences between the Tx and control groups.

-   Consequently, a data scientist may wrongfully, knowingly, or unknowingly report invalid results.

-   In addition to sampling techniques, data scientists should also aim to understand additional methodological processes and practices used to construct the RCT.

-   Engaging in morally good data science also includes purposefully inquiring about the RCT design, such as participant consent, deception/harmful practices participants had to endure, and benefits/compensation.

-   Consider that all steps taken during the research or RCT process may influence findings.

## Randomized Controlled Trials: Ethics

The Helsinki report is a historically unparalleled report that outlined a code of research ethics which inform RCTs. The World Medical Assembly established the document in 1964 [@18thworldmedicalassembly1964] in response to the Nuremberg trails and ethical concerns and documentation that spurred from experimental atrocities that occurred during the Holocaust [@schmidt2010].

## Randomized Controlled Trials: Ethics

The WMA Declaration of Helsinki is now in its tenth revision. There are currently 37 principles which are categorized under 10 broad categories [WMA Declaration of Helsinki](https://www.wma.net/policies-post/wma-declaration-of-helsinki/). The following categories and summarized principles which may closely relate to data, analytics, and sampling:

-   Free and Informed Consent theme suggests that:

    -   consent to participate in a research study must be voluntary.

    -   participants are aware that they may withdraw at any point throughout the study.

    -   researchers need to confirm that participants understand the consent forms.

## Randomized Controlled Trials: Ethics

-   Risks, Burdens, and Benefits theme suggests that:

    -   research including human participants may be conducted if the importance of the research objective outweighs the risk to the participants.

-   Minimizing Harm theme suggests that:

    -   research should be conducted in a manner that avoids or minimizes harm to the environment and participants.

    -   harmed participants due to study's treatment are give appropriate compensation.

## 8. Randomized Controlled Trials: Tuskegee Syphilis Study

The Tuskegee Syphilis study is a primary example that demonstrates the implications of not upholding research ethics [@tuskegee1997].

-   Conducted by the [U.S. Public Health Service (USPHS)](https://www.cdc.gov/tuskegee/about/index.html) from 1932 to 1972.

-   399 Black males with late latent-syphilis and 201 Black males without the disease were recruited to participate in an "experimental study" that would provide treatment for their "bad blood".

-   However, researchers used deception and never provided treatment and prevented participants to receive treatment outside of the study.

-   Participants' compensation included free meals, free medical exams, and burial insurance.

-   According to records approximately 28-100 participants died from their syphilis diagnosis.

# Observational Studies

## 9. Observational Studies

<br>
<br>

> "Excellent methods of analysis will not salvage a poorly designed *observational* study"
>
> -- Rosenbaum, 2010

-   Simple observational study:

    -   is an empirical study of effects caused by treatments when a randomized RCT is unethical or not feasible [@rosenbaum2010]. 

    - Observations are not subjected to randomization, but rather natural circumstances divide individuals into groups, those with and/or without the natural circumstance.

## {.instructor-discussion}
<<<<<<< Updated upstream
The following are some examples where observational studies may be needed because randomization is not ethical:

  + Classic examples include measuring the effect of smoking or drinking alcohol on health.  In general, cannot ethically randomly assign any exposure that may cause harm.  
  + Randomly denying access to helpful treatments, etc., when it is reliably available would also be unethical. This includes denying access to basic needs and rights around education, housing etc.
=======
The following are questions for student and points to be made 

- What are some examples where observational studies may be needed because randomization is not ethical?

  + Classic examples include measuring the effect of smoking or drinking alcohol on health.  In general, cannot ethically randomly assign any exposure that may cause harm.  

  + Randomly denying access to helpful treatments etc when it is reliably available would also be unethical. This includes denying access to basic needs and rights around education, housing etc.

>>>>>>> Stashed changes
  + Examples that may violate autonomy and personal choice?
  
##  9. Observational Study  

- Two types: natural or structured: 
  -  **Natural**: observe people or other units in an environment in which behaviors naturally occur.
     - Ex. documenting shoppers behaviors at a mall. 

  - **Structured**: carefully document one or more specific behaviors in a particular setting. 

    - Most medical observational studies are structured. 

- Researchers take extreme caution and use various methodological techniques when using an observational study to evaluate Tx effects.

- Methodological practices include participant matching based on background features of interest, such as age, sex, ethnicity. Creating pairs is key to determine if the Tx truly impacted the participants in the Tx group.
      

##  9. Observational Study

-   Observational studies face many challenges

    -   In general, data scientists should pay special attention to observations recruitment, study procedures, and survey/assessment selection.

    -   Since, observational studies are not true experiments, researchers and data scientists can expect bias in samples and lower confidence in analytic findings along with other limitations [Jhangiani, Cuttler, Leighton, 2019](https://kpu.pressbooks.pub/psychmethods4e/chapter/overview-of-non-experimental-research/).
    
    - Ethical practices that data scienists can engage while working with data from observational studies includes: 
      - Communicating with stakeholders that findings are not absolute truths.
      - Educating readers that correlation does not equal causation
      - Use statistical techniques, such as weights or conservative statistics, to deal with unequal representation and analytical confidence.  


# Simpson's Paradox

## 10. Simpson's Paradox: UC Berkeley Graduate Admissions

```{r, width = 300, height = 700}
#| fig-align: center
# Load necessary library
library(ggplot2)
library(dplyr)
library(tidyr)


admissions <- tribble(
  ~Department, ~Group,  ~Applicants, ~AdmitRate,
  "A",         "Men",     825,        0.62,
  "A",         "Women",   108,        0.82,
  "B",         "Men",     560,        0.63,
  "B",         "Women",   25,         0.68,
  "C",         "Men",     325,        0.37,
  "C",         "Women",   593,        0.34,
  "D",         "Men",     417,        0.33,
  "D",         "Women",   375,        0.35,
  "E",         "Men",     191,        0.28,
  "E",         "Women",   393,        0.24,
  "F",         "Men",     373,        0.06,
  "F",         "Women",   341,        0.07
)

#Compute admitted counts
admissions <- admissions %>%
  mutate(Admitted = round(Applicants * AdmitRate))

# Summarize total admitted by group
group_summary <- admissions %>%
  group_by(Group) %>%
  summarise(Applicants = sum(Applicants),
            Admitted = sum(Admitted),
            AdmitRate = Admitted / Applicants)
# Plot bar chart of total admitted
TotalGA<- ggplot(group_summary, aes(x = Group, y = 100*AdmitRate, fill = Group)) +
  geom_bar(stat = "identity") +
  labs(title = "Perecentage of Applicants Admitted by Gender",
       x = "Group",
       y = "Percentage Admitted") +
  theme_bw(base_size=16) +
  # scale_fill_manual(values = c("Men" = "#1f77b4", "Women" = "#ff7f0e")) +
  theme(legend.position = "none") + 
  ylim(c(0, 100))

TotalGA
```


## {.instructor-discussion}

What are some possible explanations for the discrepancy in the previous plot?

Possibilities:

- The difference is due to random chance (sampling variability)
- Female applicants were less qualified than male applicants
- UC Berkeley was biased against women
- Confounding or lurker variables (the real explanation, described in the following slides)

This example can also fit into the [storytelling and visualization module](https://github.com/SCC4DS/data-science-ethics/tree/main/visualization) to highlight the number of different possible explanations for the same (limited) set of data.

## {.instructor-note}

From wikipedia:

The admission figures for the fall of 1973 showed that men applying were more likely than women to be admitted, and the difference was so large that it was unlikely to be due to chance. However, when taking into account the information about departments being applied to, the different rejection percentages reveal the different difficulty of getting into the department, and at the same time it showed that women tended to apply to more competitive departments with lower rates of admission, even among qualified applicants (such as in the English department), whereas men tended to apply to less competitive departments with higher rates of admission (such as in the engineering department). The pooled and corrected data showed a "small but statistically significant bias in favor of women".

## 10. Simpson's Paradox: UC Berkeley Graduate Admissions

```{r, width = 300, height = 700 }
#| fig-align: center
library(patchwork)
# Manually enter the data
df <- data.frame(
  Department = c("A", "B", "C", "D", "E", "F", "Total"),
  All_Applicants = c(933, 585, 918, 792, 584, 714, 4526),
  All_AdmitRate = c(0.64, 0.63, 0.35, 0.34, 0.25, 0.06, 0.39),
  Men_Applicants = c(825, 560, 325, 417, 191, 373, 2691),
  Men_AdmitRate = c(0.62, 0.63, 0.37, 0.33, 0.28, 0.06, 0.45),
  Women_Applicants = c(108, 25, 593, 375, 393, 341, 1835),
  Women_AdmitRate = c(0.82, 0.68, 0.34, 0.35, 0.24, 0.07, 0.30)
)

# Step 2: Reshape department-level data (exclude Total row)
df_long <- df %>%
  filter(Department != "Total") %>%
  select(Department, Men_AdmitRate, Women_AdmitRate) %>%
  pivot_longer(cols = c(Men_AdmitRate, Women_AdmitRate),
               names_to = "Gender",
               values_to = "AdmitRate") %>%
  mutate(Gender = ifelse(Gender == "Men_AdmitRate", "Men", "Women"))

# Step 3: Extract total rates for horizontal lines
total_men <- df %>% filter(Department == "Total") %>% pull(Men_AdmitRate)
total_women <- df %>% filter(Department == "Total") %>% pull(Women_AdmitRate)

# Step 4: Plot
BGS<- ggplot(df_long, aes(x = Department, y = AdmitRate, fill = Gender)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = total_men, linetype = "dashed", color = "#F8766D", linewidth = 1) +
  geom_hline(yintercept = total_women, linetype = "dashed", color = "#00BFC4", linewidth = 1) +
  scale_y_continuous(labels = scales::percent, limits = c(0, 1)) +
  labs(
    title = "Percent of applicants admitted by gender and deparment",
    subtitle = "Dashed lines indicate total admission rates by gender)",
    x = "Department",
    y = "Admission Rate"
  ) +
  theme_bw(base_size=16) +
  theme(
    plot.title = element_text(face = "bold"),
    legend.position = "top"
  )

BGS
```
<center>How is this possible?</center>

## 10. Simpson's Paradox: UC Berkeley Graduate Gender Discrimination

```{r}
prop_applying <- admissions |> group_by(Group) |> mutate(Applied = Applicants/sum(Applicants)) |> ungroup() |>
  group_by(Department) |> mutate(OverallAdmit = sum(Admitted)/sum(Applicants)) |> ungroup() |>
  ggplot(aes(x=Department, y=Applied, fill=Group)) + geom_bar(stat="identity", position="dodge") +
  ylab("Proportion Applying")

admissions_rate <- admissions |> group_by(Group) |> mutate(Applied = Applicants/sum(Applicants)) |> ungroup() |>
  group_by(Department) |> mutate(OverallAdmit = sum(Admitted)/sum(Applicants)) |> ungroup() |>
  ggplot(aes(x=Department, y=OverallAdmit)) + geom_bar(stat="identity", position="dodge") + ylab("Percent Admitted") + ylim(c(0, 1))

prop_applying / admissions_rate
```



<!-- ## Berkeley Gender Discrimination {.smaller} -->


<!-- | Department | All |  | Men |  | Women |  | -->
<!-- |------------|------|------|------|------|---------|------| -->
<!-- |            | Applicants | Admitted | Applicants | Admitted | Applicants | Admitted | -->
<!-- | A | 933 | 64% | <span style="background-color: #FFEB99">825</span> | 62% | 108 | <span style="background-color: #90EE90">82%</span> | -->
<!-- | B | 585 | 63% | <span style="background-color: #FFEB99">560</span> | 63% | 25 | <span style="background-color: #90EE90">68%</span> | -->
<!-- | C | 918 | 35% | 325 | <span style="background-color: #90EE90">37%</span> | <span style="background-color: #FFEB99">593</span> | 34% | -->
<!-- | D | 792 | 34% | <span style="background-color: #FFEB99">417</span> | 33% | 375 | <span style="background-color: #90EE90">35%</span> | -->
<!-- | E | 584 | 25% | 191 | <span style="background-color: #90EE90">28%</span> | <span style="background-color: #FFEB99">393</span> | 24% | -->
<!-- | F | 714 | 6% | <span style="background-color: #FFEB99">373</span> | 6% | 341 | <span style="background-color: #90EE90">7%</span> | -->
<!-- | Total | 4526 | 39% |  <span style="background-color: #FFEB99">2691</span> |  <span style="background-color: #90EE90">45%</span> | 1835 | 30% | -->

<!-- - <span style="background-color: #90EE90">Green</span>: greater percentage of successful applicants than  -->
<!-- the other gender -->

<!-- - <span style="background-color: #FFEB99">Yellow</span>: greater number of applicants than the other gender -->

## {.instructor-note}

For the previous plots, point out that that women tended to apply to departments that had much lower acceptance rate.  There was no major gender differences, once accounting for departmental preference.




## 10. Simpson's Paradox: Define

-   Simpson’s Paradox is a statistical phenomenon in which a trend that appears across multiple subgroups tends to **reverse or disappear** when the groups are combined.

-   Correlations between variables can exist for many different reasons.  Sometimes correlation is due to some kind of causation, but often there is a simple explanation related to confounding variables or selection effects. Stratifying according to confounding variables can make associations disappear.

- Randomized control trials balance confounders (e.g., departmental preference) across groups, but aren't always ethically feasible.

- Simpson's paradox highlights one way in which statistics (from observational data) can be misused or misinterpreted.

## {.instructor-discussion}

Summary discussion questions

- Discuss some of the tradeoffs between conducting a randomized experiment and using observational data. 

- What are the ethical benefits and barriers in running randomized experiments?
  + Pro: Results will reflect the population (on average)
  + Challenges: previously discussed issues with the ethics of assigning treatments

- What are the ethical concerns associated with "natural experiments"? 
  + Data collection & privacy concerns
  + Dangers in drawing conclusions with reasoning over relevant confounders.  May not know what confounders to include. Expertise needed to reason about results carefully.
  + Can increase prevalence of misinformation or misleading conclusions if not reported carefully.

## References
